name: BVLC-GoogLeNet # name of your model
framework:
  name: Caffe # framework for the model
  version: 1.0 # framework version contraint
version: 1.0 # version information in semantic version format
container: # containers used to perform model prediction
           # multiple platforms can be specified
  amd64:
    gpu: raiproject/carml-caffe:amd64-cpu
    cpu: raiproject/carml-caffe:amd64-gpu
  ppc64le:
    cpu: raiproject/carml-caffe:ppc64le-gpu
    gpu: raiproject/carml-caffe:ppc64le-gpu
description: >
  This model is a replication of the model described in the GoogleNet publication. We would like to thank Christian Szegedy for all his help in the replication of GoogleNet model.
  Differences:
  not training with the relighting data-augmentation;
  not training with the scale or aspect-ratio data-augmentation;
  uses "xavier" to initialize the weights instead of "gaussian";
  quick_solver.prototxt uses a different learning rate decay policy than the original solver.prototxt, that allows a much faster training (60 epochs vs 250 epochs);
  The bundled model is the iteration 2,400,000 snapshot (60 epochs) using quick_solver.prototxt
  This bundled model obtains a top-1 accuracy 68.7% (31.3% error) and a top-5 accuracy 88.9% (11.1% error) on the validation set, using just the center crop. (Using the average of 10 crops, (4 + 1 center) * 2 mirror, should obtain a bit higher accuracy.)
references: # references to papers / websites / etc.. describing the model
  - https://arxiv.org/pdf/1409.4842.pdf
  - https://github.com/BVLC/caffe/tree/master/models/bvlc_googlenet
# license of the model
license: unrestricted
# inputs to the model
inputs:
  # first input type for the model
  - type: image
    # description of the first input
    description: the input image
    parameters: # type parameters
      dimensions: [1, 3, 224, 224]
      mean: https://github.com/Robert0812/deepsaldet/raw/master/caffe-sal/data/ilsvrc12/imagenet_mean.binaryproto
output:
  # the type of the output
  type: feature
  # a description of the output parameter
  description: the output label
  parameters:
    # type parameters
    features_url: https://gist.githubusercontent.com/anonymous/a824ba333ba92293ae80dd8d667d3911/raw/b2d1d2cada37ea14818ab7c3e229c49bb22c4535/gistfile1.txt
model: # specifies model graph and weights resources
  graph_path: https://raw.githubusercontent.com/BVLC/caffe/master/models/bvlc_googlenet/deploy.prototxt
  weights_path: http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel
  is_archive: false # if set, then the base_url is a url to an archive
                    # the graph_path and weights_path then denote the
                    # file names of the graph and weights within the archive
attributes: # extra network attributes
  kind: CNN # the kind of neural network (CNN, RNN, ...)
  training_dataset: ImageNet # dataset used to for training
  manifest_author: abduld
